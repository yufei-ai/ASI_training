{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#K Nearest Neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN is a simple classification algorithm. It classifies cases based on a similarity measure relying on the labels belonging to the K nearest points in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import neighbors as neigh\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import feature_selection\n",
    "from sklearn import preprocessing\n",
    "\n",
    "%matplotlib inline  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define all the functions we need to implement KNN classification algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarity: Calculate the distance between two data instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Define Euclidean Distance: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def euclideanDistance(instance1, instance2):\n",
    "    length = len(instance1)\n",
    "    # you can also check if instance1 and instance2 have the same length\n",
    "    distance = 0\n",
    "    for l in range(length):\n",
    "        distance += (instance1[l] - instance2[l])**2\n",
    "    return math.sqrt(distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data1 = [0,1,2]\n",
    "data2 = [0,2,4]\n",
    "distance = euclideanDistance(data1, data2)\n",
    "print 'Distance: ', distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a function to get the K nearest neighbors of a point in a set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getNeighbors(data, labels, testInstance, K):\n",
    "    distances = []\n",
    "    neighbors = {}\n",
    "    #Finds the distances between all the points and creates a list of tuples.\n",
    "    for i in range(len(data)):\n",
    "        dist = euclideanDistance(testInstance, data[i, :])\n",
    "        distances.append([data[i,:], dist])\n",
    "\n",
    "    #Sorts the list of distances by using the second element of the tuple, i.e. the distance    \n",
    "\n",
    "    idx = np.argsort(np.array(distances)[:, 1])\n",
    "    neighbors_data = data[idx]\n",
    "    neighbors_label = labels[idx]\n",
    "    \n",
    "    neighbors =  {'data': neighbors_data[:K], 'labels': neighbors_label[:K]}\n",
    "    return neighbors\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define the training set: 2 points and 2 labels\n",
    "data = np.array([[2, 2, 2], [4, 4, 4]])\n",
    "labels = np.array([0, 1])\n",
    "\n",
    "# define the test instance\n",
    "testInstance = [5, 5, 5]\n",
    "\n",
    "# choose the number of neighbours\n",
    "K = 1\n",
    "\n",
    "# find & retrieve the K nearest points to the test instance, sorted by the distance\n",
    "neighbors = getNeighbors(data, labels, testInstance, K)\n",
    "print(neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Response: count the number of times a certain class appears in the set of neighbours. The class with the highest frequency will be the label assigned to the test instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getResponse(neighbors):\n",
    "    classVotes = {}\n",
    "    #Assign the votes for every class\n",
    "    for i in range(len(neighbors)):\n",
    "        response = neighbors[i]\n",
    "        if response in classVotes:\n",
    "            classVotes[response] += 1\n",
    "        else:\n",
    "            classVotes[response] = 1\n",
    "    \n",
    "    #Use the dictionary to short which class has the most votes\n",
    "    sortedVotes = sorted(classVotes.iteritems(), key=operator.itemgetter(1), reverse=True)\n",
    "    #print sortedVotes\n",
    "    return sortedVotes[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# in this case we have two 1s and one 0: class 1 wins.\n",
    "\n",
    "neighbors['labels'] = np.array([1, 1, 0])\n",
    "response = getResponse(neighbors['labels'])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: test the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getAccuracy(testSet, predictions):\n",
    "    correct = 0\n",
    "    for i in range(len(testSet)):\n",
    "        #If the label of the testSet and the prediction are the same add one.\n",
    "        if testSet[i] == predictions[i]:\n",
    "            correct += 1\n",
    "    return (float(correct)/float(len(testSet))) * 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# true labels\n",
    "testSet = np.array(['a','a','b'])\n",
    "\n",
    "# predicted labels\n",
    "predictions = ['a', 'a', 'a']\n",
    "\n",
    "accuracy = getAccuracy(testSet, predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** <br> Assign a label to the test instance, basing on the following training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_set = np.array([[1, 1, 1], [1, 3, 5], [7, 5, 4], [9, 5, 3]])\n",
    "training_labels = np.array([1, 2, 1, 2])\n",
    "test_instance = np.array([4, 4, 4])\n",
    "\n",
    "# get K neighbours\n",
    "K = 1\n",
    "neighbours = getNeighbors(training_set, training_labels, testInstance, K)\n",
    "\n",
    "# get the label\n",
    "label = getResponse(neighbours['labels'])\n",
    "\n",
    "print label\n",
    "\n",
    "# what about the accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And now, with real data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have all the tools we need to classify data. Now we want to test the algorithm over real data, namely the Statlog (German Credit Data) Data Set (http://bit.ly/1K3bcku). Each customer is described by a set of numbers (features), and we want to decide automatically whether he or she is a \"good\" or a \"bad\" customer. This means we are in a binary classification setup. \n",
    "\n",
    "First, we want to read and explore our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv('german.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the algorithm, we need to split the data into training and test set, and convert to Numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, train_size = 0.7)\n",
    "\n",
    "train_X = np.array(train)[:, :24]\n",
    "train_Y = np.array(train)[:,24]\n",
    "\n",
    "test_X = np.array(test)[:, :24]\n",
    "test_Y = np.array(test)[:,24]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - NN algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions=[]\n",
    "K = 1\n",
    "for i in range(len(test_Y)):\n",
    "    neighbors = getNeighbors(train_X, train_Y, test_X[i,:], K)\n",
    "    result = getResponse(neighbors['labels'])\n",
    "    predictions.append(result)\n",
    "accuracy = getAccuracy(test_Y, predictions)\n",
    "print 'Accuracy: ', accuracy, '%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use sklearn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = neigh.KNeighborsClassifier(K)\n",
    "clf.fit(train_X, train_Y)\n",
    "\n",
    "predictions1 = clf.predict(test_X)\n",
    "\n",
    "accuracy = getAccuracy(test_Y, predictions1)\n",
    "print('Accuracy: ' + repr(accuracy) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Normalizing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have a look at the values in the data, we can see that they have different orders of magnitude for different features. A normalization step might be required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute mean and standard deviation of training set\n",
    "mean = np.mean(train_X, axis=0)\n",
    "std = np.std(train_X, axis=0)\n",
    "\n",
    "# note that we scale test set using the mean and std of the training set\n",
    "train_Xscaled = (train_X-mean)/std\n",
    "test_Xscaled = (test_X-mean)/std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "K = 1\n",
    "clf = neigh.KNeighborsClassifier(K)\n",
    "clf.fit(train_Xscaled, train_Y)\n",
    "\n",
    "predictions = clf.predict(test_Xscaled)\n",
    "\n",
    "accuracy = getAccuracy(test_Y, predictions)\n",
    "print('Accuracy: ' + repr(accuracy) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also investigate other metrics, such as: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_names= ['good', 'bad']\n",
    "print(sklearn.metrics.classification_report(test_Y, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also try setting weights to see if our performance increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "K = 1\n",
    "clf = neigh.KNeighborsClassifier(K, weights='distance')\n",
    "clf.fit(train_X, train_Y)\n",
    "\n",
    "predictions = clf.predict(test_X)\n",
    "\n",
    "# accuracy = getAccuracy(test_Y, predictions)\n",
    "accuracy = sklearn.metrics.accuracy_score(test_Y, predictions)*100\n",
    "print('Accuracy: ' + repr(accuracy) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we increase the  number of neighbours taken into account? We can plot the accuracy accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plotvector(train_X, train_Y, test_X, test_Y, weights, upperLim = 100):\n",
    "    results = []\n",
    "    for k in range(1, upperLim, 4):\n",
    "        clf = neigh.KNeighborsClassifier(n_neighbors = k, weights = weights)\n",
    "        clf = clf.fit(train_X, train_Y)\n",
    "        preds = clf.predict(test_X)\n",
    "        accuracy = clf.score(test_X, test_Y)\n",
    "        results.append([k, accuracy*100])\n",
    " \n",
    "    results = np.array(results)\n",
    "    return(results)\n",
    "\n",
    "pltvector1 = plotvector(train_X, train_Y, test_X, test_Y, weights = \"uniform\")\n",
    "pltvector2 = plotvector(train_X, train_Y, test_X, test_Y,  weights = \"distance\")\n",
    "line1 = plt.plot(pltvector1[:,0], pltvector1[:,1], label = \"uniform\")\n",
    "line2 = plt.plot(pltvector2[:,0], pltvector2[:,1], label = \"distance\")\n",
    "plt.legend(loc=3)\n",
    "plt.ylim(60, 80)\n",
    "plt.title(\"Accuracy with Increasing K\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do a step of feature selection, in order to maintain only the most descriptive features. More specifically, the sklearn.feature_selection module can be used for feature selection/dimensionality reduction on sample sets, either to improve estimatorsâ€™ accuracy scores or to boost their performance on very high-dimensional datasets. Univariate feature selection works by selecting the best features based on univariate statistical tests.\n",
    "\n",
    "First, we select the optimal number of features, through cross validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "percentiles = range(1, 100, 5)\n",
    "results = []\n",
    "for i in range(1, 100, 5):\n",
    "    fs = feature_selection.SelectPercentile(sklearn.feature_selection.f_classif, percentile=i)\n",
    "    X_train_fs = fs.fit_transform(train_Xscaled, train_Y)\n",
    "    scores = sklearn.cross_validation.cross_val_score(clf, X_train_fs, train_Y, cv=5)\n",
    "    results = np.append(results, scores.mean())\n",
    "\n",
    "optimal_percentil = np.where(results == results.max())[0]\n",
    "print \"Optimal percentil :{0}\".format(percentiles[optimal_percentil]), \"\\n\"\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "import pylab as pl\n",
    "pl.figure()\n",
    "pl.xlabel(\"Number of features selected\")\n",
    "pl.ylabel(\"Cross validation accuracy)\")\n",
    "pl.plot(percentiles,results)\n",
    "print \"Mean scores:\",results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we select the relevant features and we repeat the KNN algorithm with the transformed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fs = sklearn.feature_selection.SelectPercentile(sklearn.feature_selection.f_classif, percentile=percentiles[optimal_percentil])\n",
    "X_train_fs = fs.fit_transform(train_Xscaled, train_Y)\n",
    "\n",
    "clf = sklearn.neighbors.KNeighborsClassifier(5)\n",
    "\n",
    "clf.fit(X_train_fs, train_Y)\n",
    "X_test_fs = fs.transform(test_Xscaled)\n",
    "predictions = clf.predict(X_test_fs)\n",
    "\n",
    "accuracy = getAccuracy(test_Y, predictions)\n",
    "print('Accuracy: ' + repr(accuracy) + '%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens to accuracy if we change the ratio between training and test set?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
